import json
import os
import urllib.parse
from datetime import datetime, timedelta
from xml.etree.ElementTree import Element, SubElement, ElementTree, parse, register_namespace
import yaml

# Register the atom namespace
register_namespace('atom', 'http://www.w3.org/2005/Atom')

# Load configuration
with open('config.yaml', 'r') as file:
    config = yaml.safe_load(file)

# MAX_ITEMS = config.get('max_items', 50)
# MAX_AGE_DAYS = config.get('max_age_days', 30)

def read_json_files(directory):
    json_data = []
    for filename in os.listdir(directory):
        if filename.endswith('_rewritten.json'):
            filepath = os.path.join(directory, filename)
            with open(filepath, 'r') as f:
                data = json.load(f)
                json_data.append(data)
    return json_data

def create_rss_feed(json_data, output_path):
    # Load existing RSS feed if it exists
    if os.path.exists(output_path):
        tree = parse(output_path)
        rss = tree.getroot()
        channel = rss.find('channel')
    else:
        rss = Element('rss')
        rss.set('version', '2.0')
        rss.set('xmlns:atom', 'http://www.w3.org/2005/Atom')
        channel = SubElement(rss, 'channel')

        title = SubElement(channel, 'title')
        title.text = "Feed di Notizie UglyCitizen"

        link = SubElement(channel, 'link')
        link.text = "https://github.com/fabriziosalmi/UglyFeed"

        description = SubElement(channel, 'description')
        description.text = "Feed di notizie aggregato e riscritto da UglyCitizen"

        language = SubElement(channel, 'language')
        language.text = "it"

        # Add the atom:link element
        atom_link = SubElement(channel, 'atom:link')
        atom_link.set('href', 'https://github.com/fabriziosalmi/UglyFeed/uglyfeeds/uglyfeed.xml')
        atom_link.set('rel', 'self')
        atom_link.set('type', 'application/rss+xml')

    # Filter and add new items
    new_items = []
    cutoff_date = datetime.now() - timedelta(days=MAX_AGE_DAYS)
    for item in json_data:
        processed_at = datetime.strptime(item.get('processed_at', datetime.now().isoformat()), '%Y-%m-%d %H:%M:%S')
        if processed_at >= cutoff_date:
            item_element = Element('item')

            item_title = SubElement(item_element, 'title')
            item_title.text = item.get('title', 'Nessun Titolo')

            item_description = SubElement(item_element, 'description')
            content = item.get('content', 'Nessun Contenuto')

            # Append source links to the description
            if 'links' in item:
                content += "<br/><br/><small><b>Fonti</b></small><br/><ul>"
                for link in item['links']:
                    content += f'<li><small><a href="{link}" target="_blank">{link}</a></small></li>'
                content += "</ul>"

            # Append model and API information
            api = item.get('api', 'Unknown API')
            model = item.get('model', 'Unknown Model')
            content += f'<br/><br/><small>Generated by <b>{model}</b> via <b>{api.capitalize()}</b></small>'

            item_description.text = content

            pubDate = SubElement(item_element, 'pubDate')
            pubDate.text = processed_at.strftime('%a, %d %b %Y %H:%M:%S GMT')

            # Add guid element
            guid = SubElement(item_element, 'guid')
            guid.text = "https://github.com/fabriziosalmi/UglyFeed/{}".format(urllib.parse.quote(item.get('title', 'Nessun Titolo')))

            new_items.append(item_element)

    # Get existing items and combine with new ones
    existing_items = list(channel.findall('item'))
    all_items = existing_items + new_items
    all_items.sort(key=lambda x: datetime.strptime(x.find('pubDate').text, '%a, %d %b %Y %H:%M:%S GMT'), reverse=True)

    # Trim the list to max items
    trimmed_items = all_items[:MAX_ITEMS]

    # Clear current items in channel and add trimmed list back
    for item in channel.findall('item'):
        channel.remove(item)
    for item in trimmed_items:
        channel.append(item)

    # Save the updated RSS feed
    tree = ElementTree(rss)
    tree.write(output_path, encoding='utf-8', xml_declaration=True)

def main():
    rewritten_dir = 'rewritten'
    output_path = os.path.join('uglyfeeds', 'uglyfeed.xml')

    os.makedirs('uglyfeeds', exist_ok=True)

    json_data = read_json_files(rewritten_dir)

    if json_data:
        create_rss_feed(json_data, output_path)
        print(f'RSS feed successfully created at {output_path}')
    else:
        print('No JSON files found in the rewritten directory.')

if __name__ == '__main__':
    main()
